# UniChat 应用程序用户手册

## 一、引言
UniChat 是一款智能助手应用程序，它整合了多个大语言模型（LLM）和知识库文档，旨在为用户提供准确且有用的答案。本手册将指导您完成该应用程序的安装、配置和使用。

## 二、安装

### 2.1 获取安装包
UniChat 以安装包的形式进行分发。您可以从[下载](https://gitcode.com/2301_77468151/UniChatApp/releases)。

### 2.2 启动应用程序
安装完成后，您可以像启动其他普通应用程序一样启动 UniChat。启动后，会弹出一个控制台窗口，应用程序将启动一个 HTTP 服务器。几秒钟后，会自动为您打开一个网页。您可以从该网页开始操作。

## 三、配置

### 3.1 环境变量配置
`.env` 文件用于存储环境变量，例如不同大语言模型（LLM）提供商的 API 密钥和基础 URL。以下是一些常见的 LLM 提供商及其配置示例：
```plaintext
OPENAI_API_KEY=
MOONSHOT_API_KEY=
BAICHUAN_API_KEY=
DEEPSEEK_API_KEY=
DASHSCOPE_API_KEY=
```
您需要根据自己的需求在相应字段中填写对应的 API 密钥。如果您没有相关的 API 密钥，可以联系相应的提供商进行申请。
注意：`.env` 文件是可选的。您也可以将 API 密钥直接填入环境变量中。

### 3.2 部署配置
![img_1.png](resources\unichat1.png)
![img_2.png](resources\unichat2.png)

### 3.3 知识库配置
![img_3.png](resources\unichat3.png)

您可以根据自己的需求选择合适的 LLM 提供商和模型，以及嵌入向量提供商和模型。如果 `LLM_MODEL` 或 `EMB_MODEL` 字段为空，应用程序将使用提供商部分定义的默认模型。

### 3.4 Ollama 安装
在开始聊天之前，您需要下载并安装 Ollama 应用程序。

### 3.5 模型下载
该应用程序支持本地模型部署。因此，您还需要下载特定的 LLM 模型。
LLM 模型通常体积较大。您可能希望为它们指定一个特定的存储位置。您可以从系统托盘打开 Ollama 设置并指定具体位置。
![img_4.png](resources\unichat4.png)
![img_5.png](resources\unichat5.png)

## 四、使用说明

### 4.1 打开聊天界面
启动应用程序后，在浏览器中输入 `http://localhost:63342/unichat/frontend/index.html` 以打开聊天界面。实际上，在应用程序启动时会自动打开该界面。

### 4.2 提问并获取答案
在聊天界面的输入框中输入您的问题，然后点击“发送”按钮。应用程序将把问题发送给智能助手，答案将显示在聊天窗口中。

### 4.3 配置模型和知识库
点击聊天界面右上角的配置按钮（齿轮图标）以打开配置窗口。在配置窗口中，您可以选择不同的 LLM 提供商和模型，以及嵌入向量提供商和模型。您还可以查看和管理知识库文档。

### 4.4 上传知识库文档
如果您需要上传自己的知识库文档，可以使用应用程序提供的 API。具体操作方法，请参考开发文档或联系技术支持团队。

## 五、常见问题解答

### 5.1 未找到模型
如果应用程序提示本地未找到某个模型，您可以在终端中使用 `Ollama pull <模型名称>` 命令下载该模型。

### 5.2 网络错误
如果遇到网络错误，请检查您的网络连接，并确保 `.env` 文件中的 API 密钥和基础 URL 正确。

### 5.3 服务器错误
如果收到服务器错误，请查看应用程序的日志文件（`run.log`，位于应用程序的根目录）以获取更详细的信息。您也可以尝试重启应用程序。

## 六、联系我们
如果您在使用过程中遇到任何问题或有任何建议，请随时联系我们的技术支持团队。我们将竭诚为您提供帮助。

以上是 UniChat 应用程序的用户手册。希望本手册能帮助您顺利使用该应用程序。如果您有任何其他问题，请参考本手册或随时与我们联系。 